{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ARC Prize 2025 - Model Training\n\nTrain neural network models for ARC pattern recognition.\n\n**Author:** Andrew Jewell Sr.  \n**Company:** AutomataNexus, LLC  \n**Date:** September 26, 2024\n\n## Models:\n1. **MINERVA** - Strategic Pattern Analysis & Decision Making\n2. **ATLAS** - Spatial Transformations & Structural Support  \n3. **IRIS** - Color Pattern Recognition & Harmony\n4. **CHRONOS** - Temporal Sequences & Evolution Detection\n5. **PROMETHEUS** - Creative Pattern Generation & Foresight",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Installation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Install required packages\n!pip install torch torchvision matplotlib numpy pandas tqdm onnx onnxruntime plotly scikit-learn\n\n# For Colab GPU info\n!nvidia-smi"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Clone repository from GitHub\n!git clone https://github.com/AutomataControls/Arc2025.git\n%cd Arc2025\n\n# Or if you need to upload files manually:\n# from google.colab import files\n# uploaded = files.upload()  # Upload arc_models.py and other files"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\nimport numpy as np\nimport json\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport os\nfrom typing import Dict, List, Tuple\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport pandas as pd\nfrom datetime import datetime\n\n# Import our models\nfrom models.arc_models import (\n    MinervaNet, AtlasNet, IrisNet, ChronosNet, PrometheusNet,\n    create_models\n)\n\n# Set device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'Using device: {device}')\nif torch.cuda.is_available():\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    print(f'Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ARC dataset\n",
    "!wget https://github.com/fchollet/ARC-AGI/raw/main/data/training.tar.gz\n",
    "!tar -xzf training.tar.gz\n",
    "!wget https://github.com/fchollet/ARC-AGI/raw/main/data/evaluation.tar.gz\n",
    "!tar -xzf evaluation.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCDataset(Dataset):\n",
    "    \"\"\"ARC dataset with pattern labeling for training\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str, max_grid_size: int = 30):\n",
    "        self.max_grid_size = max_grid_size\n",
    "        self.tasks = []\n",
    "        self.pattern_labels = {\n",
    "            'rotation': 0, 'reflection': 1, 'scaling': 2, 'translation': 3,\n",
    "            'color_mapping': 4, 'symmetry': 5, 'object_movement': 6,\n",
    "            'counting': 7, 'logical': 8, 'composite': 9\n",
    "        }\n",
    "        \n",
    "        # Load all JSON files\n",
    "        for filename in os.listdir(data_path):\n",
    "            if filename.endswith('.json'):\n",
    "                with open(os.path.join(data_path, filename), 'r') as f:\n",
    "                    task = json.load(f)\n",
    "                    task['filename'] = filename\n",
    "                    self.tasks.append(task)\n",
    "        \n",
    "        # Create training pairs with pseudo-labels\n",
    "        self.pairs = []\n",
    "        for task in self.tasks:\n",
    "            for example in task.get('train', []):\n",
    "                self.pairs.append({\n",
    "                    'input': np.array(example['input']),\n",
    "                    'output': np.array(example['output']),\n",
    "                    'task_id': task['filename'],\n",
    "                    'pattern_label': self._detect_pattern_type(example)\n",
    "                })\n",
    "        \n",
    "        print(f\"Loaded {len(self.tasks)} tasks with {len(self.pairs)} training pairs\")\n",
    "        \n",
    "        # Pattern distribution\n",
    "        pattern_counts = {}\n",
    "        for pair in self.pairs:\n",
    "            label = pair['pattern_label']\n",
    "            pattern_name = list(self.pattern_labels.keys())[label]\n",
    "            pattern_counts[pattern_name] = pattern_counts.get(pattern_name, 0) + 1\n",
    "        print(\"\\nPattern distribution:\")\n",
    "        for pattern, count in sorted(pattern_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            print(f\"  {pattern}: {count} ({count/len(self.pairs)*100:.1f}%)\")\n",
    "    \n",
    "    def _detect_pattern_type(self, example: Dict) -> int:\n",
    "        \"\"\"Simple heuristic to assign pattern labels\"\"\"\n",
    "        input_grid = np.array(example['input'])\n",
    "        output_grid = np.array(example['output'])\n",
    "        \n",
    "        # Check for size changes (scaling)\n",
    "        if input_grid.shape != output_grid.shape:\n",
    "            if output_grid.size > input_grid.size:\n",
    "                return self.pattern_labels['scaling']\n",
    "            else:\n",
    "                return self.pattern_labels['counting']\n",
    "        \n",
    "        # Check for rotations\n",
    "        for k in [1, 2, 3]:\n",
    "            if np.array_equal(np.rot90(input_grid, k), output_grid):\n",
    "                return self.pattern_labels['rotation']\n",
    "        \n",
    "        # Check for reflections\n",
    "        if np.array_equal(np.flip(input_grid, axis=0), output_grid):\n",
    "            return self.pattern_labels['reflection']\n",
    "        if np.array_equal(np.flip(input_grid, axis=1), output_grid):\n",
    "            return self.pattern_labels['reflection']\n",
    "        \n",
    "        # Check for color changes\n",
    "        if set(input_grid.flatten()) != set(output_grid.flatten()):\n",
    "            return self.pattern_labels['color_mapping']\n",
    "        \n",
    "        # Check for symmetry\n",
    "        if (np.array_equal(output_grid, np.flip(output_grid, axis=0)) or \n",
    "            np.array_equal(output_grid, np.flip(output_grid, axis=1))):\n",
    "            return self.pattern_labels['symmetry']\n",
    "        \n",
    "        # Default to composite\n",
    "        return self.pattern_labels['composite']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        pair = self.pairs[idx]\n",
    "        \n",
    "        # Convert to one-hot encoding\n",
    "        input_grid = self._grid_to_tensor(pair['input'])\n",
    "        output_grid = self._grid_to_tensor(pair['output'])\n",
    "        pattern_label = torch.tensor(pair['pattern_label'], dtype=torch.long)\n",
    "        \n",
    "        return input_grid, output_grid, pattern_label\n",
    "    \n",
    "    def _grid_to_tensor(self, grid: np.ndarray) -> torch.Tensor:\n",
    "        \"\"\"Convert grid to one-hot tensor and pad to max size\"\"\"\n",
    "        h, w = grid.shape\n",
    "        \n",
    "        # One-hot encode\n",
    "        one_hot = np.zeros((10, self.max_grid_size, self.max_grid_size))\n",
    "        for i in range(min(h, self.max_grid_size)):\n",
    "            for j in range(min(w, self.max_grid_size)):\n",
    "                color = grid[i, j]\n",
    "                one_hot[color, i, j] = 1\n",
    "        \n",
    "        return torch.FloatTensor(one_hot)\n",
    "\n",
    "# Create dataset\n",
    "full_dataset = ARCDataset('training')\n",
    "\n",
    "# Split into train/val\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"\\nTrain size: {len(train_dataset)}, Val size: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Functions with Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \"\"\"Comprehensive model trainer with metrics tracking\"\"\"\n",
    "    \n",
    "    def __init__(self, model, model_name, device):\n",
    "        self.model = model.to(device)\n",
    "        self.model_name = model_name\n",
    "        self.device = device\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'val_loss': [],\n",
    "            'val_acc': [],\n",
    "            'learning_rates': [],\n",
    "            'pattern_accuracies': {}\n",
    "        }\n",
    "        \n",
    "        # Best model tracking\n",
    "        self.best_val_acc = 0\n",
    "        self.best_epoch = 0\n",
    "        \n",
    "    def train_epoch(self, loader, optimizer, criterion):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for input_grid, output_grid, pattern_label in tqdm(loader, desc='Training'):\n",
    "            input_grid = input_grid.to(self.device)\n",
    "            output_grid = output_grid.to(self.device)\n",
    "            pattern_label = pattern_label.to(self.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass (model-specific)\n",
    "            if self.model_name in ['minerva', 'iris']:\n",
    "                outputs = self.model(input_grid, output_grid)\n",
    "                logits = outputs['pattern_logits'] if 'pattern_logits' in outputs else outputs['pattern_type_logits']\n",
    "            elif self.model_name == 'atlas':\n",
    "                outputs = self.model(input_grid)\n",
    "                # Use transform params as proxy for pattern classification\n",
    "                transform_params = outputs['transform_params']\n",
    "                logits = transform_params[:, :10]  # First 10 dims for classification\n",
    "            elif self.model_name == 'chronos':\n",
    "                outputs = self.model([input_grid])\n",
    "                logits = outputs['evolution_type_logits']\n",
    "            elif self.model_name == 'prometheus':\n",
    "                outputs = self.model(input_grid)\n",
    "                logits = outputs['synthesis_strategy_logits'][:, :10]\n",
    "            \n",
    "            loss = criterion(logits, pattern_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            total += pattern_label.size(0)\n",
    "            correct += (predicted == pattern_label).sum().item()\n",
    "        \n",
    "        return total_loss / len(loader), correct / total\n",
    "    \n",
    "    def validate(self, loader, criterion):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for input_grid, output_grid, pattern_label in loader:\n",
    "                input_grid = input_grid.to(self.device)\n",
    "                output_grid = output_grid.to(self.device)\n",
    "                pattern_label = pattern_label.to(self.device)\n",
    "                \n",
    "                # Forward pass (same as training)\n",
    "                if self.model_name in ['minerva', 'iris']:\n",
    "                    outputs = self.model(input_grid, output_grid)\n",
    "                    logits = outputs['pattern_logits'] if 'pattern_logits' in outputs else outputs['pattern_type_logits']\n",
    "                elif self.model_name == 'atlas':\n",
    "                    outputs = self.model(input_grid)\n",
    "                    transform_params = outputs['transform_params']\n",
    "                    logits = transform_params[:, :10]\n",
    "                elif self.model_name == 'chronos':\n",
    "                    outputs = self.model([input_grid])\n",
    "                    logits = outputs['evolution_type_logits']\n",
    "                elif self.model_name == 'prometheus':\n",
    "                    outputs = self.model(input_grid)\n",
    "                    logits = outputs['synthesis_strategy_logits'][:, :10]\n",
    "                \n",
    "                loss = criterion(logits, pattern_label)\n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                total += pattern_label.size(0)\n",
    "                correct += (predicted == pattern_label).sum().item()\n",
    "                \n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(pattern_label.cpu().numpy())\n",
    "        \n",
    "        return total_loss / len(loader), correct / total, all_preds, all_labels\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=50, lr=1e-3):\n",
    "        optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=0.01)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        print(f\"\\nTraining {self.model_name.upper()} for {epochs} epochs...\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Train\n",
    "            train_loss, train_acc = self.train_epoch(train_loader, optimizer, criterion)\n",
    "            \n",
    "            # Validate\n",
    "            val_loss, val_acc, val_preds, val_labels = self.validate(val_loader, criterion)\n",
    "            \n",
    "            # Update history\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_loss)\n",
    "            self.history['val_acc'].append(val_acc)\n",
    "            self.history['learning_rates'].append(scheduler.get_last_lr()[0])\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                self.best_epoch = epoch\n",
    "                torch.save(self.model.state_dict(), f'{self.model_name}_best.pt')\n",
    "            \n",
    "            # Print progress\n",
    "            print(f'Epoch [{epoch+1}/{epochs}] '\n",
    "                  f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} '\n",
    "                  f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
    "            \n",
    "            scheduler.step()\n",
    "        \n",
    "        # Final validation with best model\n",
    "        self.model.load_state_dict(torch.load(f'{self.model_name}_best.pt'))\n",
    "        val_loss, val_acc, val_preds, val_labels = self.validate(val_loader, criterion)\n",
    "        \n",
    "        print(f\"\\nBest validation accuracy: {self.best_val_acc:.4f} at epoch {self.best_epoch+1}\")\n",
    "        \n",
    "        return val_preds, val_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create models\n",
    "models = create_models()\n",
    "\n",
    "# Training results storage\n",
    "training_results = {}\n",
    "\n",
    "# Train each model\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training {model_name.upper()} - {model.description}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    trainer = ModelTrainer(model, model_name, device)\n",
    "    \n",
    "    # Train with appropriate epochs\n",
    "    epochs = 30 if model_name in ['minerva', 'prometheus'] else 25\n",
    "    val_preds, val_labels = trainer.train(train_loader, val_loader, epochs=epochs)\n",
    "    \n",
    "    # Store results\n",
    "    training_results[model_name] = {\n",
    "        'trainer': trainer,\n",
    "        'history': trainer.history,\n",
    "        'best_acc': trainer.best_val_acc,\n",
    "        'val_preds': val_preds,\n",
    "        'val_labels': val_labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Visualizations with Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_plots(model_name, history):\n",
    "    \"\"\"Create training visualizations using Plotly\"\"\"\n",
    "    \n",
    "    # Training history plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(1, len(history['train_loss']) + 1)),\n",
    "        y=history['train_loss'],\n",
    "        name='Train Loss',\n",
    "        line=dict(color='blue', width=2)\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(1, len(history['val_loss']) + 1)),\n",
    "        y=history['val_loss'],\n",
    "        name='Val Loss',\n",
    "        line=dict(color='red', width=2)\n",
    "    ))\n",
    "    \n",
    "    # Create second y-axis for accuracy\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(1, len(history['train_acc']) + 1)),\n",
    "        y=history['train_acc'],\n",
    "        name='Train Acc',\n",
    "        line=dict(color='green', width=2, dash='dash'),\n",
    "        yaxis='y2'\n",
    "    ))\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=list(range(1, len(history['val_acc']) + 1)),\n",
    "        y=history['val_acc'],\n",
    "        name='Val Acc',\n",
    "        line=dict(color='orange', width=2, dash='dash'),\n",
    "        yaxis='y2'\n",
    "    ))\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=f'{model_name.upper()} Training History',\n",
    "        xaxis_title='Epoch',\n",
    "        yaxis=dict(title='Loss', side='left'),\n",
    "        yaxis2=dict(title='Accuracy', side='right', overlaying='y'),\n",
    "        hovermode='x unified',\n",
    "        width=800,\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_confusion_matrix_plot(model_name, y_true, y_pred, class_names):\n",
    "    \"\"\"Create confusion matrix using Plotly\"\"\"\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=cm,\n",
    "        x=class_names,\n",
    "        y=class_names,\n",
    "        colorscale='Blues',\n",
    "        text=cm,\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 12}\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'{model_name.upper()} Confusion Matrix',\n",
    "        xaxis_title='Predicted',\n",
    "        yaxis_title='True',\n",
    "        width=600,\n",
    "        height=600\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def create_performance_comparison():\n",
    "    \"\"\"Create model performance comparison chart\"\"\"\n",
    "    \n",
    "    model_names = []\n",
    "    accuracies = []\n",
    "    \n",
    "    for model_name, results in training_results.items():\n",
    "        model_names.append(model_name.upper())\n",
    "        accuracies.append(results['best_acc'] * 100)\n",
    "    \n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(\n",
    "            x=model_names,\n",
    "            y=accuracies,\n",
    "            text=[f'{acc:.1f}%' for acc in accuracies],\n",
    "            textposition='auto',\n",
    "            marker_color=['#6b46c1', '#2c5aa0', '#ff6b6b', '#4ecdc4', '#f7b731']\n",
    "        )\n",
    "    ])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Model Performance Comparison',\n",
    "        xaxis_title='Model',\n",
    "        yaxis_title='Validation Accuracy (%)',\n",
    "        yaxis_range=[0, 100],\n",
    "        width=800,\n",
    "        height=500\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Generate plots for each model\n",
    "pattern_names = ['rotation', 'reflection', 'scaling', 'translation', 'color_mapping',\n",
    "                 'symmetry', 'object_movement', 'counting', 'logical', 'composite']\n",
    "\n",
    "for model_name, results in training_results.items():\n",
    "    # Training history\n",
    "    fig_history = create_training_plots(model_name, results['history'])\n",
    "    fig_history.show()\n",
    "    fig_history.write_html(f'{model_name}_training_history.html')\n",
    "    \n",
    "    # Confusion matrix\n",
    "    fig_cm = create_confusion_matrix_plot(model_name, results['val_labels'], \n",
    "                                          results['val_preds'], pattern_names)\n",
    "    fig_cm.show()\n",
    "    fig_cm.write_html(f'{model_name}_confusion_matrix.html')\n",
    "\n",
    "# Overall comparison\n",
    "fig_comparison = create_performance_comparison()\n",
    "fig_comparison.show()\n",
    "fig_comparison.write_html('model_comparison.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate Detailed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed metrics for each model\n",
    "detailed_metrics = {}\n",
    "\n",
    "for model_name, results in training_results.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{model_name.upper()} - Detailed Performance Report\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(results['val_labels'], results['val_preds'],\n",
    "                                   target_names=pattern_names, output_dict=True)\n",
    "    \n",
    "    # Store metrics\n",
    "    detailed_metrics[model_name] = {\n",
    "        'classification_report': report,\n",
    "        'best_accuracy': results['best_acc'],\n",
    "        'parameters': sum(p.numel() for p in models[model_name].parameters()),\n",
    "        'training_time': len(results['history']['train_loss']) * 2.5  # Approximate minutes per epoch\n",
    "    }\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"Best Validation Accuracy: {results['best_acc']:.4f}\")\n",
    "    print(f\"Model Parameters: {detailed_metrics[model_name]['parameters']:,}\")\n",
    "    print(f\"\\nPer-Pattern Performance:\")\n",
    "    \n",
    "    for pattern in pattern_names:\n",
    "        if pattern in report:\n",
    "            print(f\"  {pattern:20s} - Precision: {report[pattern]['precision']:.3f}, \"\n",
    "                  f\"Recall: {report[pattern]['recall']:.3f}, \"\n",
    "                  f\"F1: {report[pattern]['f1-score']:.3f}\")\n",
    "\n",
    "# Save metrics to JSON\n",
    "with open('training_metrics.json', 'w') as f:\n",
    "    json.dump(detailed_metrics, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Convert to ONNX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "def export_to_onnx(model, model_name, example_input, device):\n",
    "    \"\"\"Export PyTorch model to ONNX format\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Prepare inputs based on model\n",
    "    onnx_path = f'{model_name}_model.onnx'\n",
    "    \n",
    "    if model_name in ['minerva', 'iris']:\n",
    "        # Two input models\n",
    "        example_output = example_input.clone()\n",
    "        inputs = (example_input, example_output)\n",
    "        input_names = ['input_grid', 'output_grid']\n",
    "    elif model_name == 'chronos':\n",
    "        # Sequence input - export with single grid\n",
    "        inputs = example_input\n",
    "        input_names = ['input_grid']\n",
    "    else:\n",
    "        # Single input models\n",
    "        inputs = example_input\n",
    "        input_names = ['input_grid']\n",
    "    \n",
    "    # Get output names from model\n",
    "    with torch.no_grad():\n",
    "        if model_name in ['minerva', 'iris']:\n",
    "            sample_out = model(example_input, example_output)\n",
    "        elif model_name == 'chronos':\n",
    "            sample_out = model([example_input])\n",
    "        else:\n",
    "            sample_out = model(example_input)\n",
    "    \n",
    "    output_names = list(sample_out.keys())\n",
    "    \n",
    "    # Export\n",
    "    print(f\"Exporting {model_name} to ONNX...\")\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        inputs,\n",
    "        onnx_path,\n",
    "        export_params=True,\n",
    "        opset_version=11,\n",
    "        do_constant_folding=True,\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "        dynamic_axes={'input_grid': {0: 'batch_size'}}\n",
    "    )\n",
    "    \n",
    "    # Verify\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(f\"✓ {model_name} exported successfully to {onnx_path}\")\n",
    "    \n",
    "    return onnx_path\n",
    "\n",
    "# Export all models\n",
    "example_input = torch.randn(1, 10, 30, 30).to(device)\n",
    "onnx_models = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    # Load best weights\n",
    "    model.load_state_dict(torch.load(f'{model_name}_best.pt'))\n",
    "    \n",
    "    # Export\n",
    "    onnx_path = export_to_onnx(model, model_name, example_input, device)\n",
    "    onnx_models[model_name] = onnx_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save All Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Create output directory locally in Colab\noutput_dir = './ARC_Models_2025'\nos.makedirs(output_dir, exist_ok=True)\n\n# Create subdirectories\nos.makedirs(f'{output_dir}/pytorch', exist_ok=True)\nos.makedirs(f'{output_dir}/onnx', exist_ok=True)\nos.makedirs(f'{output_dir}/visualizations', exist_ok=True)\nos.makedirs(f'{output_dir}/metrics', exist_ok=True)\n\n# Save PyTorch models\nfor model_name in models.keys():\n    !cp {model_name}_best.pt {output_dir}/pytorch/{model_name}_model.pt\n\n# Save ONNX models\n!cp *.onnx {output_dir}/onnx/\n\n# Save visualizations\n!cp *_training_history.html {output_dir}/visualizations/\n!cp *_confusion_matrix.html {output_dir}/visualizations/\n!cp model_comparison.html {output_dir}/visualizations/\n\n# Save metrics\n!cp training_metrics.json {output_dir}/metrics/\n\n# Create model cards\nmodel_cards = {}\nfor model_name, metrics in detailed_metrics.items():\n    model_cards[model_name] = {\n        'name': model_name.upper(),\n        'description': models[model_name].description,\n        'architecture': models[model_name].__class__.__name__,\n        'parameters': metrics['parameters'],\n        'best_accuracy': metrics['best_accuracy'],\n        'training_time_minutes': metrics['training_time'],\n        'input_shape': [10, 30, 30],\n        'framework': 'PyTorch 2.0',\n        'created_date': datetime.now().strftime('%Y-%m-%d'),\n        'author': 'Andrew Jewell Sr.',\n        'organization': 'AutomataNexus, LLC'\n    }\n\nwith open(f'{output_dir}/model_cards.json', 'w') as f:\n    json.dump(model_cards, f, indent=2)\n\n# Generate Hailo conversion script for your local machine\nhailo_script = '''#!/bin/bash\n# Convert ARC Prize 2025 ONNX models to HEF format for Hailo-8\n# Author: Andrew Jewell Sr.\n# Date: September 26, 2024\n\necho \"============================================================\"\necho \"ARC Prize 2025 - ONNX to HEF Conversion for Hailo-8\"\necho \"============================================================\"\n\n# Models to convert\nMODELS=(\"minerva\" \"atlas\" \"iris\" \"chronos\" \"prometheus\")\nBASE_DIR=\"/mnt/d/opt/ARCPrize2025\"\n\n# Activate Hailo virtual environment\necho \"Activating Hailo environment...\"\nHAILO_VENV=\"/mnt/c/Users/Juelz/hailo_venv_py310\"\nif [ -d \"$HAILO_VENV\" ]; then\n    source $HAILO_VENV/bin/activate\n    echo \"✓ Hailo environment activated\"\nelse\n    echo \"✗ Hailo environment not found at $HAILO_VENV\"\n    exit 1\nfi\n\n# Check if hailo command is available\nif ! command -v hailo &> /dev/null; then\n    echo \"✗ Hailo command not found in the environment\"\n    echo \"Please ensure Hailo DFC is installed\"\n    exit 1\nfi\n\necho \"\"\necho \"Starting conversion of ${#MODELS[@]} models...\"\necho \"\"\n\n# Create output directory\nmkdir -p \"$BASE_DIR/hef\"\n\n# Convert each model\nfor model in \"${MODELS[@]}\"; do\n    echo \"----------------------------------------\"\n    echo \"Converting $model...\"\n    echo \"----------------------------------------\"\n    \n    ONNX_FILE=\"$BASE_DIR/models/onnx/${model}_model.onnx\"\n    \n    if [ ! -f \"$ONNX_FILE\" ]; then\n        echo \"✗ ONNX file not found: $ONNX_FILE\"\n        echo \"  Skipping...\"\n        continue\n    fi\n    \n    echo \"Found ONNX file: $ONNX_FILE\"\n    \n    # Step 1: Parse ONNX to HAR\n    echo \"Step 1/3: Parsing ONNX to HAR...\"\n    hailo parser onnx \\\\\n        --hw-arch hailo8 \\\\\n        --onnx-model \"$ONNX_FILE\" \\\\\n        --output-har-path \"$BASE_DIR/${model}.har\" \\\\\n        --start-node-names input_grid\n    \n    if [ ! -f \"$BASE_DIR/${model}.har\" ]; then\n        echo \"✗ Failed to create HAR file\"\n        continue\n    fi\n    \n    # Step 2: Optimize with random calibration set\n    echo \"Step 2/3: Optimizing model...\"\n    hailo optimize \\\\\n        --hw-arch hailo8 \\\\\n        --har \"$BASE_DIR/${model}.har\" \\\\\n        --use-random-calib-set \\\\\n        --output-har-path \"$BASE_DIR/${model}_optimized.har\"\n    \n    if [ ! -f \"$BASE_DIR/${model}_optimized.har\" ]; then\n        echo \"✗ Failed to optimize model\"\n        continue\n    fi\n    \n    # Step 3: Compile to HEF\n    echo \"Step 3/3: Compiling to HEF...\"\n    hailo compiler \\\\\n        --hw-arch hailo8 \\\\\n        --har \"$BASE_DIR/${model}_optimized.har\" \\\\\n        --output-hef-path \"$BASE_DIR/hef/${model}.hef\"\n    \n    if [ -f \"$BASE_DIR/hef/${model}.hef\" ]; then\n        echo \"✓ Successfully compiled: $BASE_DIR/hef/${model}.hef\"\n        echo \"  Size: $(du -h $BASE_DIR/hef/${model}.hef | cut -f1)\"\n        \n        # Clean up intermediate files\n        rm -f \"$BASE_DIR/${model}.har\" \"$BASE_DIR/${model}_optimized.har\"\n        echo \"  Cleaned up intermediate files\"\n    else\n        echo \"✗ Failed to compile $model to HEF\"\n    fi\n    \n    echo \"\"\ndone\n\necho \"============================================================\"\necho \"Conversion Summary\"\necho \"============================================================\"\necho \"HEF files created:\"\nfor model in \"${MODELS[@]}\"; do\n    HEF_FILE=\"$BASE_DIR/hef/${model}.hef\"\n    if [ -f \"$HEF_FILE\" ]; then\n        echo \"  ✓ $model: $(du -h $HEF_FILE | cut -f1)\"\n    else\n        echo \"  ✗ $model: Not created\"\n    fi\ndone\n\necho \"\"\necho \"Next steps:\"\necho \"1. Copy HEF files to Raspberry Pi 5:\"\necho \"   scp $BASE_DIR/hef/*.hef Automata@192.168.0.54:/home/Automata/mydata/neural-nexus/arc2025/\"\necho \"\"\necho \"2. Test on Raspberry Pi with:\"\necho \"   hailortcli run /home/Automata/mydata/neural-nexus/arc2025/minerva.hef\"\necho \"\"\n\n# Deactivate virtual environment\ndeactivate 2>/dev/null || true\n'''\n\nwith open(f'{output_dir}/convert_arc_to_hef.sh', 'w') as f:\n    f.write(hailo_script)\n\nprint(f\"\\n✅ All artifacts saved to {output_dir}\")\nprint(\"\\nContents:\")\nprint(\"  - PyTorch models (.pt)\")\nprint(\"  - ONNX models (.onnx)\")\nprint(\"  - Training visualizations (.html)\")\nprint(\"  - Performance metrics (.json)\")\nprint(\"  - Hailo conversion script (.sh)\")\nprint(\"  - Model cards (.json)\")\n\n# Create a zip file with all outputs for easy download\n!cd {output_dir} && zip -r ../ARC_Models_2025.zip *\n\nprint(\"\\n📦 Created ARC_Models_2025.zip for download\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"ARC PRIZE 2025 - MODELS TRAINING COMPLETE\")\nprint(\"=\"*80)\nprint(f\"\\nDate: {datetime.now().strftime('%B %d, %Y')}\")\nprint(f\"Author: Andrew Jewell Sr.\")\nprint(f\"Organization: AutomataNexus, LLC\")\nprint(\"\\n\" + \"-\"*80)\nprint(\"MODEL PERFORMANCE SUMMARY\")\nprint(\"-\"*80)\n\nfor model_name in ['minerva', 'atlas', 'iris', 'chronos', 'prometheus']:\n    if model_name in detailed_metrics:\n        metrics = detailed_metrics[model_name]\n        print(f\"\\n{model_name.upper()} - {models[model_name].description}\")\n        print(f\"  Validation Accuracy: {metrics['best_accuracy']*100:.1f}%\")\n        print(f\"  Parameters: {metrics['parameters']:,}\")\n        print(f\"  Model Size: ~{metrics['parameters']*4/1024/1024:.1f} MB\")\n        print(f\"  Training Time: {metrics['training_time']:.0f} minutes\")\n\nprint(\"\\n\" + \"-\"*80)\nprint(\"NEXT STEPS\")\nprint(\"-\"*80)\nprint(\"1. Models saved to ./output/ARC_Models_2025\")\nprint(\"2. Transfer ONNX models to Hailo device\")\nprint(\"3. Run convert_to_hef.sh script on Hailo device\")\nprint(\"4. Upload all formats to GitHub\")\nprint(\"5. HTML reports with visualizations generated\")\nprint(\"\\n\" + \"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "source": "## 10. Download Results",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# Download the complete model package\nfrom google.colab import files\n\nprint(\"Downloading ARC_Models_2025.zip...\")\nfiles.download('ARC_Models_2025.zip')\n\nprint(\"\\n✅ Download complete!\")\nprint(\"\\nNext steps:\")\nprint(\"1. Extract ARC_Models_2025.zip on your local machine\")\nprint(\"2. Transfer ONNX models to your Raspberry Pi with Hailo-8\")\nprint(\"3. Run the convert_to_hef.sh script on the Pi\")\nprint(\"4. Push everything to GitHub\")",
   "metadata": {},
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}