<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>OLYMPUS V1 Training Theory | AutomataNexus LLC</title>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        @page {
            size: letter;
            margin: 0.5in;
        }

        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Georgia', 'Times New Roman', serif;
            background: #f0f0f0;
            color: #1a1a1a;
            line-height: 1.6;
        }

        .document {
            width: 95%;
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            position: relative;
            padding: 20px;
            min-height: 11in;
        }

        .border {
            border: 3px solid #808080;
            border-radius: 15px;
            height: 100%;
            position: relative;
            padding: 20px;
        }

        .watermark {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%) rotate(-45deg);
            font-size: 120px;
            color: rgba(224, 247, 250, 0.3);
            font-weight: bold;
            z-index: 0;
        }

        .content {
            position: relative;
            z-index: 1;
        }

        .header {
            text-align: center;
            margin-bottom: 25px;
            padding-bottom: 15px;
            border-bottom: 2px solid #808080;
        }

        .company {
            font-size: 22px;
            font-weight: bold;
            color: #808080;
            letter-spacing: 2px;
            margin-bottom: 8px;
        }

        .title {
            font-size: 36px;
            color: #1a1a1a;
            margin-bottom: 8px;
            font-weight: bold;
        }

        .subtitle {
            font-size: 16px;
            color: #808080;
            font-style: italic;
        }

        .theory-banner {
            background: linear-gradient(135deg, #e0f7fa, #ffffff);
            border-left: 6px solid #808080;
            padding: 20px;
            margin: 25px 0;
            border-radius: 8px;
        }

        .theory-text {
            font-size: 18px;
            font-weight: bold;
            text-align: center;
            color: #1a1a1a;
        }

        .equation-highlight {
            font-size: 24px;
            color: #808080;
            font-weight: bold;
            text-align: center;
            margin: 10px 0;
        }

        .section {
            margin-bottom: 30px;
        }

        .section-title {
            font-size: 22px;
            color: #1a1a1a;
            margin-bottom: 15px;
            padding-bottom: 5px;
            border-bottom: 2px solid #808080;
            font-weight: bold;
        }

        .subsection-title {
            font-size: 18px;
            color: #808080;
            margin: 20px 0 10px 0;
            font-weight: bold;
        }

        .equation-box {
            background: #f0f0f0;
            border: 2px solid #808080;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            overflow-x: auto;
        }

        .equation-label {
            font-weight: bold;
            color: #808080;
            margin-bottom: 10px;
            font-size: 14px;
        }

        .theory-box {
            background: linear-gradient(to bottom, #e0f7fa, white);
            border-left: 4px solid #808080;
            padding: 20px;
            margin: 20px 0;
            border-radius: 0 8px 8px 0;
        }

        .loss-component {
            background: white;
            border: 1px solid #cccccc;
            border-radius: 6px;
            padding: 15px;
            margin: 10px 0;
        }

        .loss-component-title {
            font-weight: bold;
            color: #1a1a1a;
            margin-bottom: 8px;
        }

        .stage-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 12px;
            margin: 20px 0;
        }

        .stage-card {
            background: linear-gradient(135deg, #e0f7fa, #ffffff);
            border: 1px solid #808080;
            border-radius: 6px;
            padding: 10px;
            text-align: center;
            font-size: 12px;
        }

        .stage-card.advanced {
            background: linear-gradient(135deg, #e0f7fa, #808080);
            color: white;
            font-weight: bold;
        }

        .architecture-diagram {
            background: #f0f0f0;
            border: 2px solid #808080;
            border-radius: 12px;
            padding: 25px;
            margin: 25px 0;
            position: relative;
        }

        .flow-diagram {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }

        .flow-item {
            background: white;
            border: 2px solid #808080;
            border-radius: 8px;
            padding: 15px;
            text-align: center;
            flex: 1;
            margin: 5px;
            min-width: 150px;
        }

        .flow-arrow {
            color: #808080;
            font-size: 24px;
            margin: 0 10px;
        }

        .parameter-table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }

        .parameter-table th {
            background: #808080;
            color: white;
            padding: 10px;
            text-align: left;
            font-weight: bold;
        }

        .parameter-table td {
            border: 1px solid #cccccc;
            padding: 10px;
        }

        .parameter-table tr:nth-child(even) {
            background: #f0f0f0;
        }

        code {
            background: #f0f0f0;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 14px;
        }

        .highlight {
            background: linear-gradient(to bottom, transparent 50%, #e0f7fa 50%);
            padding: 0 4px;
        }

        .gradient-visual {
            height: 40px;
            background: linear-gradient(to right, #1a1a1a, #404040, #808080, #999999, #cccccc, #e8e8e8, #ffffff);
            border-radius: 6px;
            margin: 20px 0;
            position: relative;
        }

        .gradient-label {
            position: absolute;
            bottom: -20px;
            font-size: 12px;
            color: #808080;
        }

        .gradient-label.start {
            left: 0;
        }

        .gradient-label.end {
            right: 0;
        }

        .footer-info {
            text-align: center;
            margin-top: 40px;
            padding-top: 20px;
            border-top: 2px solid #808080;
            color: #808080;
            font-style: italic;
        }
    </style>
</head>
<body>
    <div class="document">
        <div class="border">
            <div class="watermark">OLYMPUS</div>
            <div class="content">
                <header class="header">
                    <div class="company">AUTOMATANEXUS LLC</div>
                    <h1 class="title">OLYMPUS V1 Training Theory</h1>
                    <p class="subtitle">Foundation Ensemble Mathematics</p>
                </header>

                <div class="theory-banner">
                    <div class="theory-text">Foundation Training + Specialist Freezing + Ensemble Fusion</div>
                    <div class="equation-highlight">Target: 85%+ Performance with Basic Ensemble Synergy</div>
                </div>

                <section class="section">
                    <h2 class="section-title">1. Core Mathematical Framework</h2>
                    
                    <div class="subsection-title">1.1 OLYMPUS V1 Loss Function</div>
                    
                    <div class="equation-box">
                        <div class="equation-label">Total Loss Function</div>
                        <p>$$\mathcal{L}_{total} = \mathcal{L}_{ensemble} + \mathcal{L}_{exact} + \lambda_{sync} \mathcal{L}_{sync} + \lambda_{consensus} \mathcal{B}_{consensus} + \lambda_{fusion} \mathcal{R}_{fusion} + \lambda_{transform} \mathcal{P}_{transform}$$</p>
                    </div>

                    <div class="theory-box">
                        <p><strong>Key Innovation:</strong> The V1 loss function introduces six critical components that enable ensemble learning while preserving specialist expertise through selective parameter freezing. The ULTRA TEAL exact match bonus drives precision while other components ensure coordination.</p>
                    </div>

                    <div class="subsection-title">1.2 Component Breakdown</div>

                    <div class="loss-component">
                        <div class="loss-component-title">Ensemble Loss (Focal Cross-Entropy with Label Smoothing)</div>
                        <div class="equation-box">
                            <p>$$\mathcal{L}_{ensemble} = -\sum_{i=1}^{B} \sum_{c=1}^{C} (1-p_i^c)^\gamma y_i^c \log(p_i^c)$$</p>
                            <p>where $\gamma = 2.0$ (focal parameter) and label smoothing $\epsilon = 0.01$</p>
                        </div>
                    </div>

                    <div class="loss-component">
                        <div class="loss-component-title">ULTRA TEAL Exact Match Bonus</div>
                        <div class="equation-box">
                            <p>$$\mathcal{L}_{exact} = -\frac{1}{B} \sum_{i=1}^{B} \mathbb{1}[\hat{y}_i = y_i] \cdot \beta_{exact}$$</p>
                            <p>where $\beta_{exact} = 8.0$ (foundation level bonus), clamped at $-6.0$</p>
                        </div>
                    </div>

                    <div class="loss-component">
                        <div class="loss-component-title">Specialist Synchronization Loss</div>
                        <div class="equation-box">
                            <p>$$\mathcal{L}_{sync} = \sum_{i,j \in \mathcal{S}, i < j} \text{MSE}(\mathbf{P}_i, \mathbf{P}_j)$$</p>
                            <p>where $\mathcal{S}$ is the set of specialists and $\mathbf{P}_i$ is specialist $i$'s prediction</p>
                        </div>
                    </div>

                    <div class="loss-component">
                        <div class="loss-component-title">Consensus Score Bonus</div>
                        <div class="equation-box">
                            <p>$$\mathcal{B}_{consensus} = -\text{consensus\_score} \cdot \lambda_{consensus}$$</p>
                            <p>where consensus_score $\in [0,1]$ measures specialist agreement</p>
                        </div>
                    </div>

                    <div class="loss-component">
                        <div class="loss-component-title">Fusion Weight Regularization</div>
                        <div class="equation-box">
                            <p>$$\mathcal{R}_{fusion} = -\mathcal{H}(\mathbf{w}) = \sum_{i} w_i \log(w_i + \epsilon)$$</p>
                            <p>Entropy-based regularization for diverse weight distributions</p>
                        </div>
                    </div>

                    <div class="loss-component">
                        <div class="loss-component-title">Transformation Penalty</div>
                        <div class="equation-box">
                            <p>$$\mathcal{P}_{transform} = \text{MSE}(\text{pred\_flat}[:,:10], \text{input\_flat}[:,:10]) \cdot \lambda_{transform}$$</p>
                            <p>where $\lambda_{transform} = 0.05$ (positive value to prevent trivial copying)</p>
                        </div>
                    </div>
                </section>

                <section class="section">
                    <h2 class="section-title">2. Specialist Weight Freezing Theory</h2>
                    
                    <div class="theory-box">
                        <p><strong>Theoretical Foundation:</strong> V1 implements selective layer freezing to preserve pre-trained specialist knowledge while allowing adaptation to ensemble dynamics. Only top transformer layers and output heads are trainable.</p>
                    </div>

                    <div class="subsection-title">2.1 Layer Selection Strategy</div>
                    
                    <div class="equation-box">
                        <div class="equation-label">Gradient Mask Function</div>
                        <p>$$g(\theta) = \begin{cases}
                        1 & \text{if } \theta \in \{\text{output, final, head, classifier, decoder}\} \\
                        1 & \text{if } \theta \in \text{layer}_{i}, i \geq 6 \\
                        0 & \text{otherwise}
                        \end{cases}$$</p>
                    </div>

                    <div class="theory-box">
                        <p><strong>Why This Works:</strong> Lower transformer layers (0-5) contain fundamental feature extractors that should remain stable. Upper layers (6+) learn task-specific representations that benefit from ensemble coordination. The output heads directly map to ensemble decisions and require adaptation.</p>
                    </div>

                    <div class="subsection-title">2.2 Parameter Distribution</div>
                    
                    <table class="parameter-table">
                        <tr>
                            <th>Component</th>
                            <th>Parameters</th>
                            <th>Status</th>
                            <th>Purpose</th>
                        </tr>
                        <tr>
                            <td>Fusion Engine</td>
                            <td>~2.5M</td>
                            <td>Fully Trainable</td>
                            <td>Learn optimal specialist combination</td>
                        </tr>
                        <tr>
                            <td>Specialist Top Layers</td>
                            <td>~1.2M per specialist</td>
                            <td>Trainable</td>
                            <td>Adapt to ensemble coordination</td>
                        </tr>
                        <tr>
                            <td>Specialist Core</td>
                            <td>~8M per specialist</td>
                            <td>Frozen</td>
                            <td>Preserve pre-trained expertise</td>
                        </tr>
                    </table>
                </section>

                <section class="section">
                    <h2 class="section-title">3. 15-Stage Progressive Curriculum Theory</h2>
                    
                    <div class="theory-box">
                        <p><strong>Core Principle:</strong> The 15-stage curriculum progressively increases complexity across three dimensions: grid size (4→30), task complexity (micro→mastery), and ensemble coordination difficulty.</p>
                    </div>

                    <div class="subsection-title">3.1 Stage Progression Mathematics</div>
                    
                    <div class="equation-box">
                        <div class="equation-label">Grid Size Progression</div>
                        <p>$$G(s) = \begin{cases}
                        4 + s & \text{for } s \in [0, 4] \\
                        9 + \lfloor\frac{s-5}{2}\rfloor & \text{for } s \in [5, 10] \\
                        16 + 2(s-10) & \text{for } s \in [11, 14]
                        \end{cases}$$</p>
                    </div>

                    <div class="equation-box">
                        <div class="equation-label">Synthesis Ratio Decay</div>
                        <p>$$\rho(s) = 0.95 - 0.05s \quad \text{for } s \in [0, 14]$$</p>
                    </div>

                    <div class="subsection-title">3.2 Stage Visualization</div>
                    
                    <div class="stage-grid">
                        <div class="stage-card">Stage 0-4<br>Foundation<br>Grid: 4-8</div>
                        <div class="stage-card">Stage 5-10<br>Intermediate<br>Grid: 9-16</div>
                        <div class="stage-card advanced">Stage 11-14<br>Advanced<br>Grid: 18-30</div>
                    </div>

                    <div class="gradient-visual">
                        <span class="gradient-label start">Basic Coordination</span>
                        <span class="gradient-label end">Foundation Mastery</span>
                    </div>
                </section>

                <section class="section">
                    <h2 class="section-title">4. Training Dynamics</h2>
                    
                    <div class="subsection-title">4.1 Learning Rate Schedule</div>
                    
                    <div class="equation-box">
                        <div class="equation-label">Cosine Annealing with Warm Restarts</div>
                        <p>$$\eta_t = \eta_{min} + \frac{1}{2}(\eta_{max} - \eta_{min})(1 + \cos(\frac{T_{cur}}{T_i}\pi))$$</p>
                        <p>where $T_i = T_0 \times T_{mult}^i$ for restart $i$</p>
                    </div>

                    <div class="theory-box">
                        <p><strong>Parameters:</strong> $T_0 = 10$ epochs (initial period), $T_{mult} = 1.2$ (restart multiplier), $\eta_{min} = 0.01 \times \eta_{max}$</p>
                    </div>

                    <div class="subsection-title">4.2 Gradient Accumulation</div>
                    
                    <div class="equation-box">
                        <div class="equation-label">Effective Batch Size</div>
                        <p>$$B_{eff} = B_{actual} \times \text{accumulation\_steps} = 256 \times 3 = 768$$</p>
                    </div>
                </section>

                <section class="section">
                    <h2 class="section-title">5. Foundation Dataset Design</h2>
                    
                    <div class="theory-box">
                        <p><strong>Core Philosophy:</strong> V1 deliberately avoids data augmentation to preserve exact ARC task patterns and prevent distribution shift from original problems.</p>
                    </div>

                    <div class="subsection-title">5.1 Data Processing Pipeline</div>
                    
                    <div class="architecture-diagram">
                        <div class="flow-diagram">
                            <div class="flow-item">Load ARC<br>Challenges</div>
                            <span class="flow-arrow">→</span>
                            <div class="flow-item">Filter by<br>Grid Size</div>
                            <span class="flow-arrow">→</span>
                            <div class="flow-item">One-Hot<br>Encoding</div>
                            <span class="flow-arrow">→</span>
                            <div class="flow-item">Pad to<br>Consistent</div>
                        </div>
                    </div>

                    <div class="subsection-title">5.2 Batch Collation Strategy</div>
                    
                    <div class="equation-box">
                        <div class="equation-label">Dynamic Padding</div>
                        <p>$$\text{pad\_dims} = (\max_i h_i, \max_i w_i) \quad \forall (h_i, w_i) \in \text{batch}$$</p>
                    </div>
                </section>

                <section class="section">
                    <h2 class="section-title">6. Fusion Engine Architecture</h2>
                    
                    <div class="subsection-title">6.1 Adaptive Weighting Mechanism</div>
                    
                    <div class="equation-box">
                        <div class="equation-label">Fusion Function</div>
                        <p>$$\mathbf{Y} = \sum_{s \in \mathcal{S}} w_s(\mathbf{x}) \cdot f_s(\mathbf{x})$$</p>
                        <p>where $w_s(\mathbf{x})$ are learned input-dependent weights</p>
                    </div>

                    <div class="subsection-title">6.2 Consensus Building</div>
                    
                    <div class="equation-box">
                        <div class="equation-label">Consensus Score</div>
                        <p>$$C = \frac{1}{|\mathcal{S}|(|\mathcal{S}|-1)} \sum_{i,j \in \mathcal{S}, i \neq j} \text{sim}(\mathbf{P}_i, \mathbf{P}_j)$$</p>
                    </div>
                </section>

                <section class="section">
                    <h2 class="section-title">7. Training Optimizations</h2>
                    
                    <div class="theory-box">
                        <p><strong>Mixed Precision:</strong> V1 uses automatic mixed precision (AMP) with GradScaler for 2x faster training and 50% memory reduction.</p>
                    </div>

                    <div class="subsection-title">7.1 Performance Metrics</div>
                    
                    <table class="parameter-table">
                        <tr>
                            <th>Metric</th>
                            <th>Target</th>
                            <th>Purpose</th>
                        </tr>
                        <tr>
                            <td>Exact Match Rate</td>
                            <td>85%+</td>
                            <td>Primary performance metric</td>
                        </tr>
                        <tr>
                            <td>Consensus Score</td>
                            <td>0.6-0.8</td>
                            <td>Coordination quality</td>
                        </tr>
                        <tr>
                            <td>Fusion Entropy</td>
                            <td>1.0-1.5</td>
                            <td>Weight diversity</td>
                        </tr>
                        <tr>
                            <td>Transform Penalty</td>
                            <td>&lt; 0.1</td>
                            <td>Non-trivial solutions</td>
                        </tr>
                    </table>
                </section>

                <section class="section">
                    <h2 class="section-title">8. Key Innovations in V1</h2>
                    
                    <div class="architecture-diagram">
                        <h3 style="text-align: center; margin-bottom: 20px;">V1 Training Flow</h3>
                        
                        <div class="flow-diagram">
                            <div class="flow-item">Load Pre-trained<br>Specialists</div>
                            <span class="flow-arrow">→</span>
                            <div class="flow-item">Freeze Core<br>Layers</div>
                            <span class="flow-arrow">→</span>
                            <div class="flow-item">15-Stage<br>Curriculum</div>
                            <span class="flow-arrow">→</span>
                            <div class="flow-item">85%+ Target<br>Performance</div>
                        </div>
                    </div>

                    <div class="subsection-title">Foundation Principles</div>
                    
                    <ul style="margin-left: 20px; line-height: 1.8;">
                        <li><span class="highlight">Selective Freezing:</span> Only ~6M of ~50M parameters trained, preserving specialist knowledge</li>
                        <li><span class="highlight">ULTRA TEAL Loss:</span> 85% IoU weighting with 15% strict matching balances accuracy</li>
                        <li><span class="highlight">Progressive Curriculum:</span> 15 stages ensure robust learning from simple to complex</li>
                        <li><span class="highlight">Entropy Regularization:</span> Encourages diverse yet coordinated specialist contributions</li>
                        <li><span class="highlight">No Augmentation:</span> Preserves exact ARC patterns for authentic learning</li>
                    </ul>
                </section>

                <section class="section">
                    <h2 class="section-title">9. Comparison with V2</h2>
                    
                    <table class="parameter-table">
                        <tr>
                            <th>Aspect</th>
                            <th>V1 (Foundation)</th>
                            <th>V2 (Advanced)</th>
                        </tr>
                        <tr>
                            <td>Specialist Weights</td>
                            <td>Mostly frozen</td>
                            <td>Partially unfrozen</td>
                        </tr>
                        <tr>
                            <td>Data Augmentation</td>
                            <td>None</td>
                            <td>5 types unified</td>
                        </tr>
                        <tr>
                            <td>Batch Size</td>
                            <td>256</td>
                            <td>512</td>
                        </tr>
                        <tr>
                            <td>Loss Components</td>
                            <td>6 components</td>
                            <td>9 components</td>
                        </tr>
                        <tr>
                            <td>Target Performance</td>
                            <td>85%</td>
                            <td>90%+</td>
                        </tr>
                    </table>
                </section>

                <section class="section">
                    <h2 class="section-title">10. Implementation Best Practices</h2>
                    
                    <div class="theory-box">
                        <p><strong>Memory Optimization:</strong> Batch size 256, gradient accumulation 3 steps, mixed precision always enabled, regular cache clearing between stages.</p>
                    </div>

                    <div class="subsection-title">Training Stability</div>
                    
                    <ul style="margin-left: 20px; line-height: 1.8;">
                        <li>Gradient clipping: 0.5 (prevents explosions)</li>
                        <li>Weight decay: 2e-6 (light regularization)</li>
                        <li>Label smoothing: 0.01 (prevents overconfidence)</li>
                        <li>Warm restarts: Escape local minima</li>
                        <li>Early stopping patience: 25 epochs</li>
                    </ul>
                </section>

                <div class="footer-info">
                    <p><strong>AutomataNexus</strong> - OLYMPUS V1 Foundation Training Theory</p>
                    <p>AI Systems Engineer: Andrew G. Jewell Sr. | AGI Research & Development</p>
                    <p>Document Generated: October 2025 | System Status: Foundation Training</p>
                </div>
            </div>
        </div>
    </div>

    <script>
        window.MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']]
            }
        };
    </script>
</body>
</html>