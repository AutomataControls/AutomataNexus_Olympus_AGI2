{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üöÄ OLYMPUS AGI2 Training Notebook\n",
        "\n",
        "## V4 Enhanced Training with MEPT, LEAP, and PRISM\n",
        "\n",
        "This notebook provides all commands to train the OLYMPUS AGI2 ensemble models with the latest V4 enhancements:\n",
        "- **MEPT**: Memory-Enhanced Progressive Training\n",
        "- **LEAP**: Learning Enhancement through Adaptive Patterns\n",
        "- **PRISM**: Program Reasoning through Inductive Synthesis\n",
        "- **LEAP-PRISM Bridge**: Enhanced pattern learning\n",
        "\n",
        "### üìã Requirements:\n",
        "- GPU: A100 80GB (recommended) or V100 32GB (minimum)\n",
        "- Runtime: GPU with High-RAM\n"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Initial Setup"
      ],
      "metadata": {
        "id": "setup_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the repository\n",
        "!git clone https://github.com/AutomataControls/AutomataNexus_Olympus_AGI2.git /content/AutomataNexus_Olympus_AGI2\n",
        "\n",
        "# Install dependencies\n",
        "!cd /content/AutomataNexus_Olympus_AGI2 && pip install -r requirements.txt -q\n",
        "\n",
        "print(\"‚úÖ Repository cloned and dependencies installed!\")"
      ],
      "metadata": {
        "id": "clone_repo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download ARC datasets\n",
        "!cd /content/AutomataNexus_Olympus_AGI2 && python scripts/download_arc_datasets.py\n",
        "\n",
        "print(\"‚úÖ ARC datasets downloaded!\")"
      ],
      "metadata": {
        "id": "download_data"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify environment\n",
        "import torch\n",
        "import os\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"\\nCurrent Memory Usage:\")\n",
        "    print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "    print(f\"  Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No GPU detected! Please enable GPU in Runtime > Change runtime type\")\n",
        "\n",
        "# Check if data exists\n",
        "data_path = '/content/AutomataNexus_Olympus_AGI2/data'\n",
        "if os.path.exists(data_path):\n",
        "    files = os.listdir(data_path)\n",
        "    print(f\"\\nüìÅ Data directory contains {len(files)} files\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Data directory not found!\")"
      ],
      "metadata": {
        "id": "verify_env"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ Individual Model Training\n",
        "\n",
        "Train each model individually. Each model specializes in different aspects:\n",
        "\n",
        "- üß† **MINERVA**: Strategic Pattern Analysis\n",
        "- üåç **ATLAS**: Spatial Transformation Specialist\n",
        "- üëÅÔ∏è **IRIS**: Feature Extraction Specialist\n",
        "- ‚è∞ **CHRONOS**: Temporal Reasoning Specialist\n",
        "- üî• **PROMETHEUS**: Meta-Learning Specialist"
      ],
      "metadata": {
        "id": "individual_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# üß† Train MINERVA - Strategic Pattern Analysis\n",
        "!cd /content/AutomataNexus_Olympus_AGI2 && python scripts/training/train_minerva.py"
      ],
      "metadata": {
        "id": "train_minerva"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üåç Train ATLAS - Spatial Transformation Specialist\n",
        "!cd /content/AutomataNexus_Olympus_AGI2 && python scripts/training/train_atlas.py"
      ],
      "metadata": {
        "id": "train_atlas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üëÅÔ∏è Train IRIS - Feature Extraction Specialist\n",
        "!cd /content/AutomataNexus_Olympus_AGI2 && python scripts/training/train_iris.py"
      ],
      "metadata": {
        "id": "train_iris"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ‚è∞ Train CHRONOS - Temporal Reasoning Specialist\n",
        "!cd /content/AutomataNexus_Olympus_AGI2 && python scripts/training/train_chronos.py"
      ],
      "metadata": {
        "id": "train_chronos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üî• Train PROMETHEUS - Meta-Learning Specialist\n",
        "!cd /content/AutomataNexus_Olympus_AGI2 && python scripts/training/train_prometheus.py"
      ],
      "metadata": {
        "id": "train_prometheus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Combined Training Options"
      ],
      "metadata": {
        "id": "combined_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: Train all models sequentially\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "models = [\n",
        "    ('MINERVA', 'train_minerva.py', 'üß†'),\n",
        "    ('ATLAS', 'train_atlas.py', 'üåç'),\n",
        "    ('IRIS', 'train_iris.py', 'üëÅÔ∏è'),\n",
        "    ('CHRONOS', 'train_chronos.py', '‚è∞'),\n",
        "    ('PROMETHEUS', 'train_prometheus.py', 'üî•')\n",
        "]\n",
        "\n",
        "for model_name, script_name, emoji in models:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{emoji} Starting training for {model_name}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    result = subprocess.run([\n",
        "        'python', f'/content/AutomataNexus_Olympus_AGI2/scripts/training/{script_name}'\n",
        "    ], capture_output=True, text=True)\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"\\n{model_name} training completed in {elapsed_time/3600:.2f} hours\")\n",
        "    \n",
        "    if result.returncode != 0:\n",
        "        print(f\"‚ö†Ô∏è Error training {model_name}:\")\n",
        "        print(result.stderr)\n",
        "    else:\n",
        "        print(f\"‚úÖ {model_name} trained successfully!\")\n",
        "    \n",
        "    # Clear GPU memory between models\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"\\nüéâ All models training completed!\")"
      ],
      "metadata": {
        "id": "train_all_sequential"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option B: Run the main V4 ensemble training script\n",
        "!cd /content/AutomataNexus_Olympus_AGI2 && python scripts/training/colab_training_v4_megascale_curriculum.py"
      ],
      "metadata": {
        "id": "train_ensemble"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Monitor Training Progress"
      ],
      "metadata": {
        "id": "monitor_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Real-time training monitor\n",
        "import subprocess\n",
        "import time\n",
        "import glob\n",
        "import os\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def monitor_training(duration_minutes=60, update_interval=30):\n",
        "    \"\"\"\n",
        "    Monitor training progress\n",
        "    \n",
        "    Args:\n",
        "        duration_minutes: How long to monitor (default: 60 minutes)\n",
        "        update_interval: Update frequency in seconds (default: 30 seconds)\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    end_time = start_time + (duration_minutes * 60)\n",
        "    \n",
        "    while time.time() < end_time:\n",
        "        clear_output(wait=True)\n",
        "        \n",
        "        # Show GPU usage\n",
        "        gpu_info = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
        "        print(\"üñ•Ô∏è GPU Status:\")\n",
        "        print(gpu_info.stdout)\n",
        "        \n",
        "        # Check for latest checkpoints\n",
        "        checkpoints = glob.glob('/content/AutomataNexus_Olympus_AGI2/arc_models_v4/*_checkpoint.pt')\n",
        "        if checkpoints:\n",
        "            print(\"\\nüì¶ Latest Checkpoints:\")\n",
        "            for checkpoint in sorted(checkpoints, key=os.path.getmtime, reverse=True)[:5]:\n",
        "                size = os.path.getsize(checkpoint) / (1024**2)  # Size in MB\n",
        "                mtime = os.path.getmtime(checkpoint)\n",
        "                model_name = os.path.basename(checkpoint).split('_')[0].upper()\n",
        "                print(f\"  {model_name}: {size:.1f} MB - {time.ctime(mtime)}\")\n",
        "        \n",
        "        # Check training reports\n",
        "        reports = glob.glob('/content/AutomataNexus_Olympus_AGI2/arc_models_v4/*_report.json')\n",
        "        if reports:\n",
        "            print(\"\\nüìä Training Reports:\")\n",
        "            import json\n",
        "            for report_path in sorted(reports, key=os.path.getmtime, reverse=True)[:3]:\n",
        "                try:\n",
        "                    with open(report_path, 'r') as f:\n",
        "                        report = json.load(f)\n",
        "                    print(f\"  {report['model_name']}: Best Exact = {report.get('best_exact', 0):.2f}%\")\n",
        "                except:\n",
        "                    pass\n",
        "        \n",
        "        # Time remaining\n",
        "        elapsed = (time.time() - start_time) / 60\n",
        "        remaining = duration_minutes - elapsed\n",
        "        print(f\"\\n‚è±Ô∏è Monitor time: {elapsed:.1f}/{duration_minutes} minutes\")\n",
        "        print(f\"   Next update in {update_interval} seconds...\")\n",
        "        \n",
        "        time.sleep(update_interval)\n",
        "    \n",
        "    print(\"\\n‚úÖ Monitoring complete!\")\n",
        "\n",
        "# Run monitor for 60 minutes (adjust as needed)\n",
        "# monitor_training(duration_minutes=60, update_interval=30)"
      ],
      "metadata": {
        "id": "monitor_progress"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ Evaluate Trained Models"
      ],
      "metadata": {
        "id": "eval_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and evaluate all trained models\n",
        "import torch\n",
        "import json\n",
        "import glob\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üîç Evaluating Trained Models\\n\" + \"=\"*50)\n",
        "\n",
        "# Find all trained models\n",
        "model_files = glob.glob('/content/AutomataNexus_Olympus_AGI2/arc_models_v4/*_best.pt')\n",
        "\n",
        "if model_files:\n",
        "    print(f\"\\nüì¶ Found {len(model_files)} trained models:\")\n",
        "    \n",
        "    model_stats = []\n",
        "    for model_file in sorted(model_files):\n",
        "        model_name = os.path.basename(model_file).replace('_best.pt', '').upper()\n",
        "        try:\n",
        "            checkpoint = torch.load(model_file, map_location='cpu')\n",
        "            \n",
        "            stats = {\n",
        "                'name': model_name,\n",
        "                'val_exact': checkpoint.get('val_exact', 0),\n",
        "                'epoch': checkpoint.get('epoch', 0),\n",
        "                'stage': checkpoint.get('stage', 0),\n",
        "                'file_size': os.path.getsize(model_file) / (1024**2)  # MB\n",
        "            }\n",
        "            model_stats.append(stats)\n",
        "            \n",
        "            emoji_map = {\n",
        "                'MINERVA': 'üß†',\n",
        "                'ATLAS': 'üåç', \n",
        "                'IRIS': 'üëÅÔ∏è',\n",
        "                'CHRONOS': '‚è∞',\n",
        "                'PROMETHEUS': 'üî•'\n",
        "            }\n",
        "            emoji = emoji_map.get(model_name, 'ü§ñ')\n",
        "            \n",
        "            print(f\"\\n{emoji} {model_name}:\")\n",
        "            print(f\"  Best Validation Exact Match: {stats['val_exact']:.2f}%\")\n",
        "            print(f\"  Training Epoch: {stats['epoch']}\")\n",
        "            print(f\"  Curriculum Stage: {stats['stage']}\")\n",
        "            print(f\"  Model Size: {stats['file_size']:.1f} MB\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è Error loading {model_name}: {e}\")\n",
        "    \n",
        "    # Summary statistics\n",
        "    if model_stats:\n",
        "        avg_exact = sum(m['val_exact'] for m in model_stats) / len(model_stats)\n",
        "        best_model = max(model_stats, key=lambda x: x['val_exact'])\n",
        "        \n",
        "        print(f\"\\nüìä Summary Statistics:\")\n",
        "        print(f\"  Average Exact Match: {avg_exact:.2f}%\")\n",
        "        print(f\"  Best Model: {best_model['name']} ({best_model['val_exact']:.2f}%)\")\n",
        "        print(f\"  Total Models Trained: {len(model_stats)}\")\n",
        "else:\n",
        "    print(\"‚ùå No trained models found. Please run training first.\")\n",
        "\n",
        "# Load latest training reports\n",
        "print(\"\\nüìÑ Latest Training Reports:\")\n",
        "report_files = glob.glob('/content/AutomataNexus_Olympus_AGI2/arc_models_v4/*_training_report_*.json')\n",
        "\n",
        "if report_files:\n",
        "    # Get the 5 most recent reports\n",
        "    recent_reports = sorted(report_files, key=os.path.getmtime, reverse=True)[:5]\n",
        "    \n",
        "    for report_file in recent_reports:\n",
        "        try:\n",
        "            with open(report_file, 'r') as f:\n",
        "                report = json.load(f)\n",
        "            \n",
        "            timestamp = datetime.fromtimestamp(os.path.getmtime(report_file))\n",
        "            print(f\"\\n  üìÖ {timestamp.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "            print(f\"     Model: {report['model_name']}\")\n",
        "            print(f\"     Best Exact: {report['best_exact']:.2f}%\")\n",
        "            print(f\"     Best Val Loss: {report['best_val_loss']:.4f}\")\n",
        "            print(f\"     Total Epochs: {report.get('total_epochs', 'N/A')}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è Error loading report: {e}\")\n",
        "else:\n",
        "    print(\"  No training reports found.\")\n",
        "\n",
        "print(\"\\n‚úÖ Evaluation complete!\")"
      ],
      "metadata": {
        "id": "evaluate_models"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6Ô∏è‚É£ Troubleshooting"
      ],
      "metadata": {
        "id": "troubleshoot_section"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear GPU memory if needed\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "def clear_gpu_memory():\n",
        "    \"\"\"Clear GPU memory and show stats\"\"\"\n",
        "    print(\"üßπ Clearing GPU memory...\")\n",
        "    \n",
        "    # Show before stats\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"\\nBefore clearing:\")\n",
        "        print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        print(f\"  Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
        "    \n",
        "    # Clear memory\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    \n",
        "    # Show after stats\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"\\nAfter clearing:\")\n",
        "        print(f\"  Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
        "        print(f\"  Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
        "        print(f\"  Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved()) / 1e9:.2f} GB\")\n",
        "    \n",
        "    print(\"\\n‚úÖ GPU memory cleared!\")\n",
        "\n",
        "clear_gpu_memory()"
      ],
      "metadata": {
        "id": "clear_gpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for common issues\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "print(\"üîç Checking for common issues...\\n\")\n",
        "\n",
        "issues_found = False\n",
        "\n",
        "# Check 1: GPU availability\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"‚ùå No GPU detected! Please enable GPU in Runtime > Change runtime type\")\n",
        "    issues_found = True\n",
        "else:\n",
        "    gpu_name = torch.cuda.get_device_name(0)\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    print(f\"‚úÖ GPU detected: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
        "    \n",
        "    if gpu_memory < 32:\n",
        "        print(\"‚ö†Ô∏è  Warning: GPU has less than 32GB memory. Consider reducing batch size.\")\n",
        "        issues_found = True\n",
        "\n",
        "# Check 2: Repository exists\n",
        "repo_path = '/content/AutomataNexus_Olympus_AGI2'\n",
        "if not os.path.exists(repo_path):\n",
        "    print(\"‚ùå Repository not found! Please run the clone command first.\")\n",
        "    issues_found = True\n",
        "else:\n",
        "    print(\"‚úÖ Repository found\")\n",
        "\n",
        "# Check 3: Data exists\n",
        "data_path = os.path.join(repo_path, 'data')\n",
        "if not os.path.exists(data_path) or len(os.listdir(data_path)) < 10:\n",
        "    print(\"‚ùå Data directory missing or incomplete! Please run download_arc_datasets.py\")\n",
        "    issues_found = True\n",
        "else:\n",
        "    print(f\"‚úÖ Data directory found with {len(os.listdir(data_path))} files\")\n",
        "\n",
        "# Check 4: Required packages\n",
        "try:\n",
        "    import torch\n",
        "    import numpy\n",
        "    import tqdm\n",
        "    print(\"‚úÖ Core packages installed\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Missing required package: {e}\")\n",
        "    issues_found = True\n",
        "\n",
        "# Check 5: Model files\n",
        "models_path = os.path.join(repo_path, 'src/models')\n",
        "if os.path.exists(models_path):\n",
        "    model_files = [f for f in os.listdir(models_path) if f.endswith('_model.py')]\n",
        "    if len(model_files) >= 5:\n",
        "        print(f\"‚úÖ All {len(model_files)} model files found\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è  Only {len(model_files)} model files found (expected 5+)\")\n",
        "        issues_found = True\n",
        "else:\n",
        "    print(\"‚ùå Models directory not found!\")\n",
        "    issues_found = True\n",
        "\n",
        "if not issues_found:\n",
        "    print(\"\\nüéâ All checks passed! Ready to train.\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  Please fix the issues above before training.\")\n",
        "\n",
        "# Quick fix suggestions\n",
        "print(\"\\nüí° Quick Fixes:\")\n",
        "print(\"1. For GPU issues: Runtime > Change runtime type > GPU > A100\")\n",
        "print(\"2. For memory issues: Reduce BATCH_SIZE from 512 to 256 or 128\")\n",
        "print(\"3. For missing data: Run the data download cell\")\n",
        "print(\"4. For import errors: Run the dependency installation cell\")"
      ],
      "metadata": {
        "id": "check_issues"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}