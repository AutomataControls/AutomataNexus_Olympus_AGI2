{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® IRIS Model Training\n",
    "\n",
    "**Color Pattern Recognition Specialist**\n",
    "\n",
    "This notebook trains the IRIS model, which specializes in:\n",
    "- Color relationships and mappings\n",
    "- Conditional color transformations\n",
    "- Pattern-based color rules\n",
    "- Color embedding techniques\n",
    "- Context-dependent recoloring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository and install dependencies\n",
    "!git clone https://github.com/AutomataControls/AutomataNexus_Olympus_AGI2.git /content/AutomataNexus_Olympus_AGI2\n",
    "!cd /content/AutomataNexus_Olympus_AGI2 && pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify environment\n",
    "import torch\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# üîß Initialize IRIS Iterative Training Controller (Run this first!)\nimport json\nimport os\nimport datetime\nfrom typing import Dict, List\n\nclass IrisIterativeTrainer:\n    def __init__(self, base_dir='/content/AutomataNexus_Olympus_AGI2'):\n        self.base_dir = base_dir\n        self.iteration_log_file = f\"{base_dir}/arc_models_v4/iris_iterations.json\"\n        self.current_params = self.load_default_params()\n        self.iterations = self.load_iteration_history()\n    \n    def load_default_params(self) -> Dict:\n        return {\n            'learning_rate': 0.004,  # Moderate for color learning\n            'batch_size': 384,       # Medium batch for color patterns\n            'epochs_per_stage': 110, # Balanced epochs for color convergence\n            'color_embedding_dim': 64,  # IRIS-specific\n            'color_attention_heads': 4, # IRIS-specific\n            'mapping_weight': 1.5,   # Color mapping loss weight\n            'transformation_penalty': 0.3,  # Updated default\n            'exact_match_bonus': 10.0,      # Updated default\n            'gradient_accumulation_steps': 6,\n            'color_augmentation': True,   # IRIS-specific\n            'embedding_dropout': 0.15,    # IRIS-specific\n            'target_accuracy': 99.0,      # Added default\n            'use_mept': True,             # Added default\n            'use_leap': True,             # Added default\n            'use_prism': True             # Added default\n        }\n    \n    def load_iteration_history(self) -> List[Dict]:\n        if os.path.exists(self.iteration_log_file):\n            with open(self.iteration_log_file, 'r') as f:\n                return json.load(f)\n        return []\n    \n    def save_iteration_history(self):\n        os.makedirs(os.path.dirname(self.iteration_log_file), exist_ok=True)\n        with open(self.iteration_log_file, 'w') as f:\n            json.dump(self.iterations, f, indent=2)\n    \n    def log_iteration(self, params: Dict, results: Dict):\n        iteration = {\n            'iteration': len(self.iterations) + 1,\n            'timestamp': datetime.datetime.now().isoformat(),\n            'parameters': params.copy(),\n            'results': results.copy()\n        }\n        self.iterations.append(iteration)\n        self.save_iteration_history()\n    \n    def get_best_iteration(self) -> Dict:\n        if not self.iterations:\n            return None\n        return max(self.iterations, key=lambda x: x['results'].get('best_exact', 0))\n    \n    def suggest_next_params(self) -> Dict:\n        if len(self.iterations) < 2:\n            return self.current_params.copy()\n        \n        best = self.get_best_iteration()\n        latest = self.iterations[-1]\n        \n        suggestions = best['parameters'].copy() if best else self.current_params.copy()\n        \n        # IRIS-specific adaptive suggestions for color learning\n        if latest and best:\n            latest_exact = latest['results'].get('best_exact', 0)\n            best_exact = best['results'].get('best_exact', 0)\n            \n            if latest_exact < best_exact * 0.85:  # Performance dropped\n                # For color tasks, adjust embedding and attention\n                suggestions['learning_rate'] *= 0.7\n                suggestions['mapping_weight'] = min(2.5, suggestions['mapping_weight'] * 1.2)\n                suggestions['embedding_dropout'] = max(0.1, suggestions['embedding_dropout'] * 0.9)\n                suggestions['color_attention_heads'] = min(8, suggestions['color_attention_heads'] + 1)\n            elif latest_exact > best_exact * 1.05:  # Good improvement\n                # Increase color complexity\n                suggestions['learning_rate'] = min(0.006, suggestions['learning_rate'] * 1.05)\n                suggestions['color_embedding_dim'] = min(96, suggestions['color_embedding_dim'] + 16)\n        \n        return suggestions\n    \n    def display_history(self):\n        if not self.iterations:\n            print(\"No IRIS iterations found. Starting fresh!\")\n            return\n        \n        print(\"üìà IRIS Training History:\")\n        print(\"-\" * 85)\n        for i, iteration in enumerate(self.iterations):\n            exact = iteration['results'].get('best_exact', 0)\n            loss = iteration['results'].get('best_val_loss', float('inf'))\n            lr = iteration['parameters'].get('learning_rate', 0)\n            mapping_weight = iteration['parameters'].get('mapping_weight', 0)\n            embed_dim = iteration['parameters'].get('color_embedding_dim', 0)\n            timestamp = iteration['timestamp'][:16]\n            \n            status = \"üü¢ BEST\" if iteration == self.get_best_iteration() else \"‚ö™\"\n            print(f\"{status} Iter {i+1}: {exact:.2f}% exact | Loss: {loss:.4f} | LR: {lr:.4f} | Map: {mapping_weight:.1f} | Emb: {embed_dim} | {timestamp}\")\n        \n        print(\"-\" * 85)\n        best = self.get_best_iteration()\n        if best:\n            print(f\"üèÜ Best: Iteration {best['iteration']} with {best['results']['best_exact']:.2f}% exact match\")\n\n# Initialize IRIS trainer and suggested parameters\niris_trainer = IrisIterativeTrainer()\nsuggested_params = iris_trainer.suggest_next_params()\niris_trainer.display_history()\nprint(\"\\n‚úÖ IRIS trainer initialized! You can now run the training cells below.\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Start IRIS Training\n",
    "\n",
    "Training configuration:\n",
    "- **Architecture**: Color Attention + Mapping Networks\n",
    "- **Parameters**: ~0.9M\n",
    "- **Specialization**: Color patterns with 96% accuracy\n",
    "- **Focus**: Color embedding and mapping rule extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train IRIS model\n",
    "!cd /content/AutomataNexus_Olympus_AGI2 && python scripts/training/train_iris.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# üéØ IRIS Iterative Training with Color-Specific Parameters\nimport subprocess\nimport tempfile\nimport os\n\n# Initialize trainer if not already done\nif 'iris_trainer' not in globals():\n    print(\"Error: Run the trainer initialization cell first!\")\n    raise NameError(\"iris_trainer not defined\")\n\n# Modify these IRIS parameters as needed:\nLEARNING_RATE = suggested_params.get('learning_rate', 0.004)\nBATCH_SIZE = suggested_params.get('batch_size', 384)\nEPOCHS_PER_STAGE = suggested_params.get('epochs_per_stage', 110)\nTRANSFORMATION_PENALTY = suggested_params.get('transformation_penalty', 0.3)  # Updated\nEXACT_MATCH_BONUS = suggested_params.get('exact_match_bonus', 10.0)  # Updated\nGRADIENT_ACCUMULATION_STEPS = suggested_params.get('gradient_accumulation_steps', 6)\nUSE_MEPT = suggested_params.get('use_mept', True)\nUSE_LEAP = suggested_params.get('use_leap', True)\nUSE_PRISM = suggested_params.get('use_prism', True)\nTARGET_ACCURACY = suggested_params.get('target_accuracy', 99.0)\n\nprint(f\"üöÄ Starting IRIS training iteration {len(iris_trainer.iterations) + 1}\")\nprint(f\"Parameters: LR={LEARNING_RATE}, BS={BATCH_SIZE}, Epochs/Stage={EPOCHS_PER_STAGE}\")\nprint(f\"Loss weights: Transform penalty={TRANSFORMATION_PENALTY}, Exact bonus={EXACT_MATCH_BONUS}\")\nprint(f\"Features: MEPT={USE_MEPT}, LEAP={USE_LEAP}, PRISM={USE_PRISM}\")\nprint(f\"üéØ Target accuracy: {TARGET_ACCURACY}%\")\n\n# Create modified training script with IRIS-specific parameters\nmodified_script = f\"\"\"\nimport sys\nsys.path.append('/content/AutomataNexus_Olympus_AGI2')\nsys.path.append('/content/AutomataNexus_Olympus_AGI2/src')\n\n# Override IRIS parameters\nimport scripts.training.train_iris as train_module\ntrain_module.LEARNING_RATE = {LEARNING_RATE}\ntrain_module.BATCH_SIZE = {BATCH_SIZE}\ntrain_module.EPOCHS_PER_STAGE = {EPOCHS_PER_STAGE}\ntrain_module.TRANSFORMATION_PENALTY = {TRANSFORMATION_PENALTY}\ntrain_module.EXACT_MATCH_BONUS = {EXACT_MATCH_BONUS}\ntrain_module.GRADIENT_ACCUMULATION_STEPS = {GRADIENT_ACCUMULATION_STEPS}\ntrain_module.USE_MEPT = {USE_MEPT}\ntrain_module.USE_LEAP = {USE_LEAP}\ntrain_module.USE_PRISM = {USE_PRISM}\n\n# Override inject_exact_match_training to use 99% target\ntry:\n    import scripts.training.stage0_exact_match_boost as boost_module\n    original_inject = boost_module.inject_exact_match_training\n    def inject_with_target(*args, **kwargs):\n        kwargs['target_accuracy'] = {TARGET_ACCURACY}\n        return original_inject(*args, **kwargs)\n    boost_module.inject_exact_match_training = inject_with_target\nexcept ImportError:\n    print(\"Warning: stage0_exact_match_boost not available\")\n\n# Run IRIS training\ntrain_module.train_iris()\n\"\"\"\n\n# Write and execute the modified script\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n    f.write(modified_script)\n    script_path = f.name\n\ntry:\n    # Run the training with extended timeout for color pattern learning (12 hours max)\n    print(\"‚è∞ IRIS training timeout: 12 hours (color pattern convergence)\")\n    result = subprocess.run(\n        ['python', script_path],\n        cwd='/content/AutomataNexus_Olympus_AGI2',\n        capture_output=True,\n        text=True,\n        timeout=43200  # 12 hours for comprehensive color learning\n    )\n    \n    print(\"IRIS training output:\")\n    print(result.stdout)\n    if result.stderr:\n        print(\"Errors:\")\n        print(result.stderr)\n        \nfinally:\n    # Clean up\n    if os.path.exists(script_path):\n        os.unlink(script_path)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# üéØ IRIS Iterative Training with Color-Specific Parameters\nimport subprocess\nimport tempfile\nimport os\n\n# Modify these IRIS color-specific parameters as needed:\nLEARNING_RATE = suggested_params.get('learning_rate', 0.004)\nBATCH_SIZE = suggested_params.get('batch_size', 384)\nEPOCHS_PER_STAGE = suggested_params.get('epochs_per_stage', 110)\nCOLOR_EMBEDDING_DIM = suggested_params.get('color_embedding_dim', 64)\nCOLOR_ATTENTION_HEADS = suggested_params.get('color_attention_heads', 4)\nMAPPING_WEIGHT = suggested_params.get('mapping_weight', 1.5)\nTRANSFORMATION_PENALTY = suggested_params.get('transformation_penalty', 0.5)  # REDUCED from 0.6\nEXACT_MATCH_BONUS = suggested_params.get('exact_match_bonus', 10.0)  # INCREASED from 5.5\nGRADIENT_ACCUMULATION_STEPS = suggested_params.get('gradient_accumulation_steps', 6)\nCOLOR_AUGMENTATION = suggested_params.get('color_augmentation', True)\nEMBEDDING_DROPOUT = suggested_params.get('embedding_dropout', 0.15)\nTARGET_ACCURACY = suggested_params.get('target_accuracy', 99.0)  # NEW: 99% target!\n\nprint(f\"üöÄ Starting IRIS training iteration {len(iris_trainer.iterations) + 1}\")\nprint(f\"Parameters: LR={LEARNING_RATE}, BS={BATCH_SIZE}, Epochs/Stage={EPOCHS_PER_STAGE}\")\nprint(f\"Color config: Embed={COLOR_EMBEDDING_DIM}D, Heads={COLOR_ATTENTION_HEADS}, Dropout={EMBEDDING_DROPOUT}\")\nprint(f\"Loss weights: Mapping={MAPPING_WEIGHT}, Transform penalty={TRANSFORMATION_PENALTY}, Exact bonus={EXACT_MATCH_BONUS}\")\nprint(f\"Color augmentation: {COLOR_AUGMENTATION}\")\nprint(f\"üéØ Target accuracy: {TARGET_ACCURACY}%\")\n\n# Create modified training script with IRIS-specific parameters\nmodified_script = f\"\"\"\nimport sys\nsys.path.append('/content/AutomataNexus_Olympus_AGI2')\nsys.path.append('/content/AutomataNexus_Olympus_AGI2/src')\n\n# Override IRIS parameters\nimport scripts.training.train_iris as train_module\ntrain_module.LEARNING_RATE = {LEARNING_RATE}\ntrain_module.BATCH_SIZE = {BATCH_SIZE}\ntrain_module.EPOCHS_PER_STAGE = {EPOCHS_PER_STAGE}\ntrain_module.COLOR_EMBEDDING_DIM = {COLOR_EMBEDDING_DIM}\ntrain_module.COLOR_ATTENTION_HEADS = {COLOR_ATTENTION_HEADS}\ntrain_module.MAPPING_WEIGHT = {MAPPING_WEIGHT}\ntrain_module.TRANSFORMATION_PENALTY = {TRANSFORMATION_PENALTY}\ntrain_module.EXACT_MATCH_BONUS = {EXACT_MATCH_BONUS}\ntrain_module.GRADIENT_ACCUMULATION_STEPS = {GRADIENT_ACCUMULATION_STEPS}\ntrain_module.COLOR_AUGMENTATION = {COLOR_AUGMENTATION}\ntrain_module.EMBEDDING_DROPOUT = {EMBEDDING_DROPOUT}\n\n# Override inject_exact_match_training to use 99% target\nimport scripts.training.stage0_exact_match_boost as boost_module\noriginal_inject = boost_module.inject_exact_match_training\ndef inject_with_target(*args, **kwargs):\n    kwargs['target_accuracy'] = {TARGET_ACCURACY}\n    return original_inject(*args, **kwargs)\nboost_module.inject_exact_match_training = inject_with_target\n\n# Run IRIS training\ntrain_module.train_iris()\n\"\"\"\n\n# Write and execute the modified script\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n    f.write(modified_script)\n    script_path = f.name\n\ntry:\n    # Run the training with extended timeout for color pattern learning (12 hours max)\n    print(\"‚è∞ IRIS training timeout: 12 hours (color pattern convergence)\")\n    result = subprocess.run(\n        ['python', script_path],\n        cwd='/content/AutomataNexus_Olympus_AGI2',\n        capture_output=True,\n        text=True,\n        timeout=43200  # 12 hours for comprehensive color learning\n    )\n    \n    print(\"IRIS training output:\")\n    print(result.stdout)\n    if result.stderr:\n        print(\"Errors:\")\n        print(result.stderr)\n        \nfinally:\n    # Clean up\n    if os.path.exists(script_path):\n        os.unlink(script_path)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# üéØ IRIS Iterative Training with Custom Parameters - FIXED\nimport subprocess\nimport tempfile\nimport os\n\n# Initialize trainer if not already done\nif 'iris_trainer' not in globals():\n    print(\"Error: Run the trainer initialization cell first!\")\n    raise NameError(\"iris_trainer not defined\")\n\n# Modify these IRIS parameters as needed:\nLEARNING_RATE = suggested_params.get('learning_rate', 0.004)\nBATCH_SIZE = suggested_params.get('batch_size', 384)\nEPOCHS_PER_STAGE = suggested_params.get('epochs_per_stage', 110)\nTRANSFORMATION_PENALTY = suggested_params.get('transformation_penalty', 0.3)  # Updated\nEXACT_MATCH_BONUS = suggested_params.get('exact_match_bonus', 10.0)  # Updated\nGRADIENT_ACCUMULATION_STEPS = suggested_params.get('gradient_accumulation_steps', 6)\nUSE_MEPT = suggested_params.get('use_mept', True)\nUSE_LEAP = suggested_params.get('use_leap', True)\nUSE_PRISM = suggested_params.get('use_prism', True)\nTARGET_ACCURACY = suggested_params.get('target_accuracy', 99.0)\n\nprint(f\"üöÄ Starting IRIS training iteration {len(iris_trainer.iterations) + 1}\")\nprint(f\"Parameters: LR={LEARNING_RATE}, BS={BATCH_SIZE}, Epochs/Stage={EPOCHS_PER_STAGE}\")\nprint(f\"Loss weights: Transform penalty={TRANSFORMATION_PENALTY}, Exact bonus={EXACT_MATCH_BONUS}\")\nprint(f\"Features: MEPT={USE_MEPT}, LEAP={USE_LEAP}, PRISM={USE_PRISM}\")\nprint(f\"üéØ Target accuracy: {TARGET_ACCURACY}%\")\n\n# Create modified training script with IRIS-specific parameters\nmodified_script = f\"\"\"\nimport sys\nsys.path.append('/content/AutomataNexus_Olympus_AGI2')\nsys.path.append('/content/AutomataNexus_Olympus_AGI2/src')\n\n# Override IRIS parameters\nimport scripts.training.train_iris as train_module\ntrain_module.LEARNING_RATE = {LEARNING_RATE}\ntrain_module.BATCH_SIZE = {BATCH_SIZE}\ntrain_module.EPOCHS_PER_STAGE = {EPOCHS_PER_STAGE}\ntrain_module.TRANSFORMATION_PENALTY = {TRANSFORMATION_PENALTY}\ntrain_module.EXACT_MATCH_BONUS = {EXACT_MATCH_BONUS}\ntrain_module.GRADIENT_ACCUMULATION_STEPS = {GRADIENT_ACCUMULATION_STEPS}\ntrain_module.USE_MEPT = {USE_MEPT}\ntrain_module.USE_LEAP = {USE_LEAP}\ntrain_module.USE_PRISM = {USE_PRISM}\n\n# Override inject_exact_match_training to use 99% target\ntry:\n    import scripts.training.stage0_exact_match_boost as boost_module\n    original_inject = boost_module.inject_exact_match_training\n    def inject_with_target(*args, **kwargs):\n        kwargs['target_accuracy'] = {TARGET_ACCURACY}\n        return original_inject(*args, **kwargs)\n    boost_module.inject_exact_match_training = inject_with_target\nexcept ImportError:\n    print(\"Warning: stage0_exact_match_boost not available\")\n\n# Run IRIS training\ntrain_module.train_iris()\n\"\"\"\n\n# Write and execute the modified script\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n    f.write(modified_script)\n    script_path = f.name\n\ntry:\n    # Run the training with extended timeout for V4 mega-scale (12 hours max)\n    print(\"‚è∞ Training timeout: 12 hours (V4 mega-scale)\")\n    result = subprocess.run(\n        ['python', script_path],\n        cwd='/content/AutomataNexus_Olympus_AGI2',\n        capture_output=True,\n        text=True,\n        timeout=43200  # 12 hours for V4 mega-scale training - KEEPING YOUR ORIGINAL!\n    )\n    \n    print(\"IRIS training output:\")\n    print(result.stdout)\n    if result.stderr:\n        print(\"Errors:\")\n        print(result.stderr)\n        \nfinally:\n    # Clean up\n    if os.path.exists(script_path):\n        os.unlink(script_path)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# üéØ IRIS Iterative Training with Color-Specific Parameters\nimport subprocess\nimport tempfile\nimport os\n\n# Modify these IRIS color-specific parameters as needed:\nLEARNING_RATE = suggested_params.get('learning_rate', 0.004)\nBATCH_SIZE = suggested_params.get('batch_size', 384)\nEPOCHS_PER_STAGE = suggested_params.get('epochs_per_stage', 110)\nCOLOR_EMBEDDING_DIM = suggested_params.get('color_embedding_dim', 64)\nCOLOR_ATTENTION_HEADS = suggested_params.get('color_attention_heads', 4)\nMAPPING_WEIGHT = suggested_params.get('mapping_weight', 1.5)\nTRANSFORMATION_PENALTY = suggested_params.get('transformation_penalty', 0.5)  # REDUCED from 0.6\nEXACT_MATCH_BONUS = suggested_params.get('exact_match_bonus', 10.0)  # INCREASED from 5.5\nGRADIENT_ACCUMULATION_STEPS = suggested_params.get('gradient_accumulation_steps', 6)\nCOLOR_AUGMENTATION = suggested_params.get('color_augmentation', True)\nEMBEDDING_DROPOUT = suggested_params.get('embedding_dropout', 0.15)\nTARGET_ACCURACY = suggested_params.get('target_accuracy', 99.0)  # NEW: 99% target!\n\nprint(f\"üöÄ Starting IRIS training iteration {len(iris_trainer.iterations) + 1}\")\nprint(f\"Parameters: LR={LEARNING_RATE}, BS={BATCH_SIZE}, Epochs/Stage={EPOCHS_PER_STAGE}\")\nprint(f\"Color config: Embed={COLOR_EMBEDDING_DIM}D, Heads={COLOR_ATTENTION_HEADS}, Dropout={EMBEDDING_DROPOUT}\")\nprint(f\"Loss weights: Mapping={MAPPING_WEIGHT}, Transform penalty={TRANSFORMATION_PENALTY}, Exact bonus={EXACT_MATCH_BONUS}\")\nprint(f\"Color augmentation: {COLOR_AUGMENTATION}\")\nprint(f\"üéØ Target accuracy: {TARGET_ACCURACY}%\")\n\n# Create modified training script with IRIS-specific parameters\nmodified_script = f\"\"\"\nimport sys\nsys.path.append('/content/AutomataNexus_Olympus_AGI2')\nsys.path.append('/content/AutomataNexus_Olympus_AGI2/src')\n\n# Override IRIS parameters\nimport scripts.training.train_iris as train_module\ntrain_module.LEARNING_RATE = {LEARNING_RATE}\ntrain_module.BATCH_SIZE = {BATCH_SIZE}\ntrain_module.EPOCHS_PER_STAGE = {EPOCHS_PER_STAGE}\ntrain_module.COLOR_EMBEDDING_DIM = {COLOR_EMBEDDING_DIM}\ntrain_module.COLOR_ATTENTION_HEADS = {COLOR_ATTENTION_HEADS}\ntrain_module.MAPPING_WEIGHT = {MAPPING_WEIGHT}\ntrain_module.TRANSFORMATION_PENALTY = {TRANSFORMATION_PENALTY}\ntrain_module.EXACT_MATCH_BONUS = {EXACT_MATCH_BONUS}\ntrain_module.GRADIENT_ACCUMULATION_STEPS = {GRADIENT_ACCUMULATION_STEPS}\ntrain_module.COLOR_AUGMENTATION = {COLOR_AUGMENTATION}\ntrain_module.EMBEDDING_DROPOUT = {EMBEDDING_DROPOUT}\n\n# Override inject_exact_match_training to use 99% target\nimport scripts.training.stage0_exact_match_boost as boost_module\noriginal_inject = boost_module.inject_exact_match_training\ndef inject_with_target(*args, **kwargs):\n    kwargs['target_accuracy'] = {TARGET_ACCURACY}\n    return original_inject(*args, **kwargs)\nboost_module.inject_exact_match_training = inject_with_target\n\n# Run IRIS training\ntrain_module.train_iris()\n\"\"\"\n\n# Write and execute the modified script\nwith tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:\n    f.write(modified_script)\n    script_path = f.name\n\ntry:\n    # Run the training with extended timeout for V4 mega-scale (12 hours max)\n    print(\"‚è∞ Training timeout: 12 hours (V4 mega-scale)\")\n    result = subprocess.run(\n        ['python', script_path],\n        cwd='/content/AutomataNexus_Olympus_AGI2',\n        capture_output=True,\n        text=True,\n        timeout=43200  # 12 hours for V4 mega-scale training - KEEPING YOUR ORIGINAL!\n    )\n    \n    print(\"IRIS training output:\")\n    print(result.stdout)\n    if result.stderr:\n        print(\"Errors:\")\n        print(result.stderr)\n        \nfinally:\n    # Clean up\n    if os.path.exists(script_path):\n        os.unlink(script_path)",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# üîß IRIS Iterative Training Controller\nimport json\nimport os\nimport datetime\nfrom typing import Dict, List\n\nclass IrisIterativeTrainer:\n    def __init__(self, base_dir='/content/AutomataNexus_Olympus_AGI2'):\n        self.base_dir = base_dir\n        self.iteration_log_file = f\"{base_dir}/arc_models_v4/iris_iterations.json\"\n        self.current_params = self.load_default_params()\n        self.iterations = self.load_iteration_history()\n    \n    def load_default_params(self) -> Dict:\n        return {\n            'learning_rate': 0.004,  # Moderate for color learning\n            'batch_size': 384,       # Medium batch for color patterns\n            'epochs_per_stage': 110, # Balanced epochs for color convergence\n            'color_embedding_dim': 64,  # IRIS-specific\n            'color_attention_heads': 4, # IRIS-specific\n            'mapping_weight': 1.5,   # Color mapping loss weight\n            'transformation_penalty': 0.6,\n            'exact_match_bonus': 5.5,\n            'gradient_accumulation_steps': 6,\n            'color_augmentation': True,   # IRIS-specific\n            'embedding_dropout': 0.15     # IRIS-specific\n        }\n    \n    def load_iteration_history(self) -> List[Dict]:\n        if os.path.exists(self.iteration_log_file):\n            with open(self.iteration_log_file, 'r') as f:\n                return json.load(f)\n        return []\n    \n    def save_iteration_history(self):\n        os.makedirs(os.path.dirname(self.iteration_log_file), exist_ok=True)\n        with open(self.iteration_log_file, 'w') as f:\n            json.dump(self.iterations, f, indent=2)\n    \n    def log_iteration(self, params: Dict, results: Dict):\n        iteration = {\n            'iteration': len(self.iterations) + 1,\n            'timestamp': datetime.datetime.now().isoformat(),\n            'parameters': params.copy(),\n            'results': results.copy()\n        }\n        self.iterations.append(iteration)\n        self.save_iteration_history()\n    \n    def get_best_iteration(self) -> Dict:\n        if not self.iterations:\n            return None\n        return max(self.iterations, key=lambda x: x['results'].get('best_exact', 0))\n    \n    def suggest_next_params(self) -> Dict:\n        if len(self.iterations) < 2:\n            return self.current_params\n        \n        best = self.get_best_iteration()\n        latest = self.iterations[-1]\n        \n        suggestions = best['parameters'].copy()\n        \n        # IRIS-specific adaptive suggestions for color learning\n        latest_exact = latest['results'].get('best_exact', 0)\n        best_exact = best['results'].get('best_exact', 0)\n        \n        if latest_exact < best_exact * 0.85:  # Performance dropped\n            # For color tasks, adjust embedding and attention\n            suggestions['learning_rate'] *= 0.7\n            suggestions['mapping_weight'] = min(2.5, suggestions['mapping_weight'] * 1.2)\n            suggestions['embedding_dropout'] = max(0.1, suggestions['embedding_dropout'] * 0.9)\n            suggestions['color_attention_heads'] = min(8, suggestions['color_attention_heads'] + 1)\n        elif latest_exact > best_exact * 1.05:  # Good improvement\n            # Increase color complexity\n            suggestions['learning_rate'] = min(0.006, suggestions['learning_rate'] * 1.05)\n            suggestions['color_embedding_dim'] = min(96, suggestions['color_embedding_dim'] + 16)\n        \n        return suggestions\n    \n    def display_history(self):\n        if not self.iterations:\n            print(\"No IRIS iterations found.\")\n            return\n        \n        print(\"üìà IRIS Training History:\")\n        print(\"-\" * 85)\n        for i, iteration in enumerate(self.iterations):\n            exact = iteration['results'].get('best_exact', 0)\n            loss = iteration['results'].get('best_val_loss', float('inf'))\n            lr = iteration['parameters'].get('learning_rate', 0)\n            mapping_weight = iteration['parameters'].get('mapping_weight', 0)\n            embed_dim = iteration['parameters'].get('color_embedding_dim', 0)\n            timestamp = iteration['timestamp'][:16]\n            \n            status = \"üü¢ BEST\" if iteration == self.get_best_iteration() else \"‚ö™\"\n            print(f\"{status} Iter {i+1}: {exact:.2f}% exact | Loss: {loss:.4f} | LR: {lr:.4f} | Map: {mapping_weight:.1f} | Emb: {embed_dim} | {timestamp}\")\n        \n        print(\"-\" * 85)\n        best = self.get_best_iteration()\n        if best:\n            print(f\"üèÜ Best: Iteration {best['iteration']} with {best['results']['best_exact']:.2f}% exact match\")\n\n# Initialize IRIS trainer\niris_trainer = IrisIterativeTrainer()\niris_trainer.display_history()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## üîÑ Iterative Training & Hyperparameter Tuning\n\n**Enhanced Training Loop with Checkpoint Resuming**\n\nThis section allows you to:\n- Resume training from checkpoints\n- Adjust color-specific hyperparameters between iterations\n- Track color mapping performance improvements\n- Get automated suggestions for next iteration",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and evaluate IRIS model\n",
    "import torch\n",
    "import json\n",
    "import glob\n",
    "\n",
    "# Find IRIS model file\n",
    "model_files = glob.glob('/content/AutomataNexus_Olympus_AGI2/arc_models_v4/iris_best.pt')\n",
    "\n",
    "if model_files:\n",
    "    model_file = model_files[0]\n",
    "    checkpoint = torch.load(model_file, map_location='cpu')\n",
    "    \n",
    "    print(\"üé® IRIS Training Results:\")\n",
    "    print(f\"  Best Validation Exact Match: {checkpoint.get('val_exact', 'N/A'):.2f}%\")\n",
    "    print(f\"  Training Epoch: {checkpoint.get('epoch', 'N/A')}\")\n",
    "    print(f\"  Stage: {checkpoint.get('stage', 'N/A')}\")\n",
    "    print(f\"  Model Size: {os.path.getsize(model_file) / (1024**2):.1f} MB\")\n",
    "else:\n",
    "    print(\"‚ùå IRIS model not found. Training may still be in progress.\")\n",
    "\n",
    "# Check training reports\n",
    "report_files = glob.glob('/content/AutomataNexus_Olympus_AGI2/arc_models_v4/iris_training_report_*.json')\n",
    "if report_files:\n",
    "    latest_report = sorted(report_files)[-1]\n",
    "    with open(latest_report, 'r') as f:\n",
    "        report = json.load(f)\n",
    "    print(f\"\\nüìä Latest Training Report:\")\n",
    "    print(f\"  Best Exact Match: {report.get('best_exact', 'N/A'):.2f}%\")\n",
    "    print(f\"  Final Validation Loss: {report.get('best_val_loss', 'N/A'):.4f}\")\n",
    "    print(f\"  Training Duration: {report.get('training_time', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear GPU memory if needed\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "print(f\"Reserved: {torch.cuda.memory_reserved() / 1e9:.2f} GB\")\n",
    "print(f\"Free: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_reserved()) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Training Complete!\n",
    "\n",
    "Your IRIS model has been trained and saved to `/content/AutomataNexus_Olympus_AGI2/arc_models_v4/`\n",
    "\n",
    "**IRIS Specialization:**\n",
    "- Color pattern recognition with 96% accuracy\n",
    "- Advanced color embedding techniques\n",
    "- Conditional color transformations\n",
    "\n",
    "**AutomataNexus OLYMPUS AGI2** - *Where Neural Networks Meet Symbolic Logic*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}